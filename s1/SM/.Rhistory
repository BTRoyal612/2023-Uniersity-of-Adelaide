data %>%
ggplot(aes(log(Assets), log(MarketValue))) +
geom_point() +
geom_smooth(method=lm) +
labs(
title = "Scatterplot of MarketValue vs log(Assets)",
caption = "The log scale declusters and improves the linearity between
predictor and response, with some outliners"
)
data %>%
ggplot(aes(log(Sales), log(MarketValue))) +
geom_point() +
geom_smooth(method=lm) +
labs(
title = "Scatterplot of MarketValue vs log(Sales)",
caption = "The log scale declusters and improves the linearity between
predictor and response, with some outliners"
)
data %>%
ggplot(aes(log(Profits), log(MarketValue))) +
geom_point() +
geom_smooth(method=lm) +
labs(
title = "Scatterplot of MarketValue vs log(Profit)",
caption = "There are NaNs produced due to some negative values
in Profits, and there is a slight curvature."
)
data %>%
ggplot(aes(log(CashFlow), log(MarketValue))) +
geom_point() +
geom_smooth(method=lm) +
labs(
title = "Scatterplot of MarketValue vs log(CashFlow)",
caption = "There are NaNs produced due to some negative values
in CashFlow, and there is a slight curvature."
)
data %>%
ggplot(aes(log(Employees), log(MarketValue))) +
geom_point() +
geom_smooth(method=lm) +
labs(
title = "Scatterplot of MarketValue vs log(Employees)",
caption = "The log scale declusters and improves the linearity between
predictor and response, with some outliners"
)
M1 <- lm(MarketValue ~ log(Assets) + log(Sales) + Profits + CashFlow
+ log(Employees), data=data)
summary(M1)
gglm(M1)
bc <- boxcox(M1)
lambda <- bc$x[which.max(bc$y)]
lambda
M2 <- lm(((MarketValue^lambda - 1)/lambda) ~ log(Assets) + log(Sales) + Profits
+ CashFlow + log(Employees), data=data)
summary(M2)
gglm(M2)
new_company <- tibble(
Assets = 1065,
Sales = 642,
Profits = 30,
CashFlow = 59,
Employees = 3.5
)
transform_pred <- predict(M2, newdata=new_company, interval="prediction", level=0.95)
market_pred <- exp(log(transform_pred*lambda + 1)/lambda)
market_pred
2*(log(159.42)-log(83.35))
2log(1.91265)
2*log(1.91265)
2*(log(168.11)-log(98.98))
exp(1.059401)
2*(168.11-98.98)
2*(159.42-83.35)
250*0.6*0.4
2*(196.56-99.65)
x <- 186.03
y <- 92.69
2*(x-y)
210*0.1*0.9
x <- 196.56
y <- 101.37
2*(x-y)
knitr::opts_chunk$set(
echo = TRUE,
fig.width = 6,
fig.asp = 0.618,
out.width = "70%",
fig.align = "center",
root.dir = "../"
)
pacman::p_load(tidyverse, gglm, skimr, MASS, janitor, ggplot2)
data <- read.csv("lung_cancer.csv")
data
data <- data %>%
mutate(city = as.factor(city),
age = as.factor(age))
data
data <- clean_names(data)
skim_without_charts(data)
data %>% ggplot(aes(age, cases)) + geom_boxplot()
data %>% ggplot(aes(city, cases)) + geom_boxplot()
data <- data %>%
mutate(
prop_cases = cases / pop
)
data %>% ggplot(aes(age, prop_cases)) + geom_boxplot()
data %>% ggplot(aes(city, prop_cases)) + geom_boxplot()
M1 <- glm(cases ~ 1, offset=log(pop), family=poisson, data=data)
summary(M1)
M2 <- glm(cases ~ age + city, offset=log(pop), family=poisson, data=data)
summary(M2)
M3 <- glm(cases ~ age + city + log(pop), offset=log(pop), family=poisson, data=data)
summary(M3)
anova(M1, M2, test="Chisq")
AIC(M1)
AIC(M2)
AIC(M3)
summary(M2)$coefficients
data <- data %>%
add_column(
M2_res = residuals(M2, type="pearson")
)
data %>%
ggplot(aes(fitted(M2), M2_res)) + geom_point() +
geom_smooth()
data %>%
ggplot(aes(age, M2_res)) + geom_boxplot()
data %>%
ggplot(aes(city, M2_res)) + geom_boxplot()
new_data <- data.frame(age="40-54", city="Fredericia", pop=4000)
lambda_hat <- predict(M2, newdata=new_data, type="response")
prob <- ppois(5, lambda=lambda_hat)
prob
knitr::opts_chunk$set(
echo = TRUE,
fig.width = 6,
fig.asp = 0.618,
out.width = "70%",
fig.align = "center",
root.dir = "../"
)
pacman::p_load(tidyverse, gglm, skimr, MASS, janitor, ggplot2)
data <- read.csv("lung_cancer.csv")
data
data <- data %>%
mutate(city = as.factor(city),
age = as.factor(age))
data
data <- clean_names(data)
skim_without_charts(data)
data %>% ggplot(aes(age, cases)) + geom_boxplot()
data %>% ggplot(aes(city, cases)) + geom_boxplot()
data <- data %>%
mutate(
prop_cases = cases / pop
)
data %>% ggplot(aes(age, prop_cases)) + geom_boxplot()
data %>% ggplot(aes(city, prop_cases)) + geom_boxplot()
M1 <- glm(cases ~ 1, offset=log(pop), family=poisson, data=data)
summary(M1)
M2 <- glm(cases ~ age + city, offset=log(pop), family=poisson, data=data)
summary(M2)
M3 <- glm(cases ~ age + city + log(pop), offset=log(pop), family=poisson, data=data)
summary(M3)
anova(M1, M2, test="Chisq")
AIC(M1)
AIC(M2)
AIC(M3)
summary(M2)$coefficients
data <- data %>%
add_column(
M2_res = residuals(M2, type="pearson")
)
data %>%
ggplot(aes(fitted(M2), M2_res)) + geom_point() +
geom_smooth()
data %>%
ggplot(aes(age, M2_res)) + geom_boxplot()
data %>%
ggplot(aes(city, M2_res)) + geom_boxplot()
new_data <- data.frame(age="40-54", city="Fredericia", pop=4000)
lambda_hat <- predict(M2, newdata=new_data, type="response")
prob <- ppois(5, lambda=lambda_hat)
prob
k <- 15
lg_lik <- -493.86
aic <- 2*(k-lg_lik)
k <- 15
lg_lik <- -493.86
aic <- 2*(k-lg_lik)
aic
aic <- 168
k <- 5
n <- 170
aicc <- aic + (2*k*(k+1))/(n-k-1)
aicc
aic <- 127
k <- 7
n <- 160
lg_lik <- k - (aic/2)
bic <- log(n)*k - 2*lg_lik
bic
install.packages("Metrics")
library(Metrics)
y <- c(10,3,2,1,4)
predicted <- c(11,3,2,0,3)
res4 <- mae(predicted, y)
library(Metrics)
y <- c(10,3,2,1,4)
predicted <- c(11,3,2,0,3)
res4 <- mae(predicted, y)
res4
library(Metrics)
y <- c(6,1,2,7,8)
predicted <- c(5,2,1,8,8)
res4 <- rmse(predicted, y)
library(Metrics)
y <- c(6,1,2,7,8)
predicted <- c(5,2,1,8,8)
res5 <- rmse(predicted, y)
res5
k <- 15
lg_lik <- -493.86
aic <- 2*(k-lg_lik)
aic
k <- 17
lg_lik <- -493.86
aic <- 2*(k-lg_lik)
aic
# Q1
k <- 17
lg_lik <- -493.86
aic <- 2*(k-lg_lik)
aic
aic <- 192
k <- 9
n <- 100
aicc <- aic + (2*k*(k+1))/(n-k-1)
aicc
aic <- 102
k <- 5
n <- 110
lg_lik <- k - (aic/2)
bic <- log(n)*k - 2*lg_lik
bic
# Q4
library(Metrics)
y <- c(10,3,2,1,4)
predicted <- c(11,3,2,0,3)
res4 <- mae(predicted, y)
res4
library(Metrics)
y <- c(10,3,9,1,2)
predicted <- c(11,3,10,1,3)
res5 <- rmse(predicted, y)
res5
b1 <- 0.5
exp(b1)
x <- 2.2
b0 <- 2.3
b1 <- 1.1
eta <- b0 + x*b1
y <- exp(eta)
y
X <- c(1,2,3,4,5)
Y <- c(2,5,5,9,9)
x0 <- 6
y_mean <- mean(Y)
y_mean
x <- 2.2
b0 <- 2.5
b1 <- 1.4
eta <- b0 + x*b1
y <- exp(eta)
y
b1 <- 0.5
exp(b1)
x <- 2.2
b0 <- 2.5
b1 <- 1.4
eta <- b0 + x*b1
y <- exp(eta)
y
Y <- c(7,9,4,9,5)
X <- c(1,2,3,4,5)
Y <- c(7,9,4,9,5)
x0 <- 6
y_mean <- mean(Y)
y_mean
install.packages("MASS")
library(MASS)
k <- 2
sigma2 <- 2
obs <- c(7,6,10,7,4)
pred <- c(7,8,8,8,4)
res <- obs - pred
rss <- sum(res^2)
mae <- mean(abs(res))
mse <- mean(res^2)
ss_total <- sum((obs - mean(obs))^2)
r2 <- 1-rss/ss_total
rss
mae
mse
r2
ss_total <- sum((obs - mean(obs))^2)
r2 <- 1-rss/ss_total
n <- length(obs)  # number of observations
adj_r2 <- 1 - (1 - r2) * ((n - 1) / (n - k - 1))
adj_r2
r2
r2 <- cor(obs, pred)^2
r2
Cp <- (rss + 2*k*sigma2)/n
Cp
MCp <- rss/sigma2 + 2*k - n
MCp
MCp <- rss/sigma2 + 2*k - n
MCp
# Q3
library(MASS)
k <- 3
sigma2 <- 2
obs <- c(7,6,10,7,4)
pred <- c(7,8,8,8,4)
n <- length(obs)
res <- obs - pred
rss <- sum(res^2)
mae <- mean(abs(res))
mse <- mean(res^2)
r2 <- cor(obs, pred)^2
MCp <- rss/sigma2 + 2*k - n
MCp
library(MASS)
k <- 3
sigma2 <- 2
obs <- c(7,6,10,7,4)
pred <- c(7,8,8,8,4)
n <- length(obs)
res <- obs - pred
rss <- sum(res^2)
mae <- mean(abs(res))
mse <- mean(res^2)
r2 <- cor(obs, pred)^2
MCp <- rss/sigma2 + 2*k - n
rss
mae
mse\
mse
r2
MCp
lambda <- 2
X <- c(-2,-1,0,1,2)
Y <- c(1.4,0.4,3.4,-3.6,-1.6)
M1 <- lm(Y~X)
X_matrix <- M1.matrix()
X_matrix <- model.matrix(M1)
lambda <- 2
X <- c(-2,-1,0,1,2)
Y <- c(1.4,0.4,3.4,-3.6,-1.6)
M1 <- lm(Y~X)
X_matrix <- model.matrix(M1)
beta <- solve(T(X_matrix)*X_matrix + lambda)*T(X_matrix)*Y
beta <- solve(t(X_matrix) %*% X_matrix %+% lambda) %*% t(X_matrix) %*% Y
beta <- solve(t(X_matrix) %*% X_matrix + lambda) %*% t(X_matrix) %*% Y
beta
beta <- solve(t(X_matrix) %*% X_matrix + lambda*I) %*% t(X_matrix) %*% Y
beta <- solve(t(X_matrix) %*% X_matrix + lambda*(diag(ncol(X_matrix)))) %*% t(X_matrix) %*% Y
beta
lambda <- 2
X <- c(-2,-1,0,1,2)
Y <- c(1.4,0.4,3.4,-3.6,-1.6)
M1 <- lm(Y~X)
X_matrix <- model.matrix(M1)
I <- diag(ncol(X_matrix))
beta <- solve(t(X_matrix) %*% X_matrix + lambda*I %*% t(X_matrix) %*% Y
beta
# Q6
lambda <- 2
X <- c(-2,-1,0,1,2)
Y <- c(1.4,0.4,3.4,-3.6,-1.6)
M1 <- lm(Y~X)
X_matrix <- model.matrix(M1)
I <- diag(ncol(X_matrix))
beta <- solve(t(X_matrix) %*% X_matrix + lambda*I) %*% t(X_matrix) %*% Y
beta
lambda <- 4
X <- c(-2,-1,0,1,2)
Y <- c(1.4,0.4,3.4,-3.6,-1.6)
M1 <- lm(Y~X)
X_matrix <- model.matrix(M1)
I <- diag(ncol(X_matrix))
beta <- solve(t(X_matrix) %*% X_matrix + lambda*I) %*% t(X_matrix) %*% Y
beta
x <- 2.2
b0 <- 2.5
b1 <- 1.4
eta <- b0 + x*b1
y <- exp(eta)
y
# Q4
X <- c(1,2,3,4,5)
Y <- c(7,9,4,9,5)
x0 <- 6
y_mean <- mean(Y)
y_mean
# Q6
lambda <- 4
X <- c(-2,-1,0,1,2)
Y <- c(1.4,0.4,3.4,-3.6,-1.6)
M1 <- lm(Y~X)
X_matrix <- model.matrix(M1)
I <- diag(ncol(X_matrix))
beta <- solve(t(X_matrix) %*% X_matrix + lambda*I) %*% t(X_matrix) %*% Y
beta
0.7563 + 1.0076*2
exp(0.7563 + 1.0076*2) / (1+exp(0.7563 + 1.0076*2)
)
19*0.5
1180.8*0.2
11*0.8*0.2
2*(186.03-92.69)
210*0.9*0.1
153.81-149.70
149.70-94.42
55.28*2
4.11*2
exp( 1.98613 )
1.04436+1.98021*1.3+log(8)
exp(5.698075)
1.07989+1.96403*0.18
exp(1.433415)
setwd("D:/2023-University-of-Adelaide/s1/SM")
k <- 17
lg_lik <- -493.86
aic <- 2*(k-lg_lik)
aic
aic <- 186
k <- 10
n <- 200
aicc <- aic + (2*k*(k+1))/(n-k-1)
aicc
aic <- 127
k <- 7
n <- 160
lg_lik <- k - (aic/2)
bic <- log(n)*k - 2*lg_lik
bic
library(Metrics)
y <- c(3,6,10,4,7)
predicted <- c(4,6,9,3,6)
res4 <- mae(predicted, y)
res4
library(Metrics)
y <- c(8,1,4,2,5)
predicted <- c(9,0,4,3,4)
res5 <- rmse(predicted, y)
res5
10.19766 + 5.35207 + 0.07293
10.19766 - 5.35207
log(9)-log(1/4)
1 - pchisq(121.81, df = 96)
exp(0.955424)
-0.002047+0.017735
1.09615+2.01407*2
exp(5.12429)/(1+exp(5.12429))
x = c(1,2,3,4,5) #time data - numeric predictor
X <- matrix(1,nrow = length(x), ncol = 2) #design matrix
X[,2] <- x
X
n = c(10,10,10,10,10)
y = c(8,5,2,1,10)
v <- log((y + 0.5)/(n-y+0.5))
b0 = solve(t(X) %*% X) %*% t(X) %*% v
b0 #initial estimate of beta
eta <- (-4)
pi <- exp(eta)/(1+exp(eta))
pi
eta <- (-4)
pi <- exp(eta)/(1+exp(eta))
pi
y_i <- 76
n_i <- 90
r_i <- (y_i-n_i*pi)/sqrt(n_i*pi*(1-pi))
r_i
x = c(1,2,3,4,5)
y = c(2,5,4,3,1)
M1 <- lm(y~x)
V_sqrt <- diag(1 / sqrt(x))
y_trans <- V_sqrt %*% y
X <- model.matrix(M1)
X_trans <- V_sqrt %*% X
X_trans
M2 <- lm(y_trans ~ X_trans - 1)
summary(M2)
x <- c(1,2,3,4,5)
X <- matrix(1, nrow = length(x), ncol=2)
X[,2] <- x
X
n <- c(10,10,10,10,10)
y <- c(0,2,6,7,9)
b0 <- c(-4, 1.2)
b0
eta = X %*% b0
eta
pii <- exp(eta)/(1+exp(eta))
npii = n*pii
npii
D <- matrix(0,nrow=5,ncol=5)
diag(D) <- npii*(1-pii)
b1 <- b0 + solve(t(X) %*% D %*% X) %*% t(X) %*% (y-npii)
b1
